# Ensemble-and-random-forest-learning
basic concept to understand the Ensemble and random forest


**What is Ensemble learning?
Ensemble learning is one of the most powerful machine learning techniques that use the combined output of two or more models/weak learners and solve a particular computational intelligence problem. E.g., a Random Forest algorithm is an ensemble of various decision trees combined.


Type of Ensemble technique

1) Voting   :   A voting ensemble (or a “ majority voting ensemble “)

2) Bagging and pasting : Bagging, also known as bootstrap aggregation.Bagging is used when our objective is to reduce the variance of a decision tree. Here the concept is to create a few subsets of data from the training sample, which is chosen randomly with replacement. Now each collection of subset data is used to prepare their decision trees thus, we end up with an ensemble of various models. The average of all the assumptions from numerous tress is used, which is more powerful than a single decision tree.
3) 
4) Random forest
5) Boosting 
6) Stacking

